# Experimental Directory

This directory contains tools, demos, and test results for Ocean Scraper development and validation.

## ğŸ“ Directory Structure

```
experimental/
â”œâ”€â”€ tools/               # Development and testing tools
â”‚   â””â”€â”€ simple-crawler.js   # Multi-page crawler demonstration
â”œâ”€â”€ demos/               # Demo scripts and examples  
â”œâ”€â”€ test-results/        # Real-world scraping test results
â”‚   â”œâ”€â”€ SCRAPING_RESULTS_SUMMARY.md  # Comprehensive test summary
â”‚   â”œâ”€â”€ wikipedia/       # Wikipedia scraping results
â”‚   â”œâ”€â”€ pathofexile/     # Gaming forum scraping results
â”‚   â””â”€â”€ crawler/         # Multi-page crawling results
â””â”€â”€ README.md           # This file
```

## ğŸ› ï¸ Tools

### Multi-Page Crawler (`tools/simple-crawler.js`)
A demonstration crawler that shows multi-page scraping capabilities:

```bash
# Basic usage
node experimental/tools/simple-crawler.js "https://example.com" 2 5

# Arguments: URL, max-depth, max-pages
```

**Features**:
- Depth-based crawling (follows links to specified depth)
- Polite crawling with delays
- Link extraction and filtering
- Comprehensive result tracking
- JSON and Markdown output

**Example Results**:
- âœ… Path of Exile forums: 6 pages, 2 depths, 100% success
- âœ… Wikipedia articles: 5 pages, 2 depths, 100% success

## ğŸ“Š Test Results

### Real-World Website Testing
Our test results demonstrate Ocean Scraper working successfully on:

- **Wikipedia**: Complex articles with multilingual support
- **Gaming Forums**: Dynamic content and user-generated content
- **Documentation Sites**: Technical content with structured data
- **JavaScript-Heavy Sites**: Properly rendered dynamic content

### Performance Metrics
- **Success Rate**: 100% across all tested sites
- **Response Times**: 4-7 seconds average
- **Content Quality**: Perfect HTMLâ†’Markdown conversion
- **Multi-Page**: Successful depth-based crawling

See `test-results/SCRAPING_RESULTS_SUMMARY.md` for complete details.

## ğŸ§ª Demos

This directory is reserved for demonstration scripts and examples showing Ocean Scraper capabilities.

## ğŸ”§ Development Guidelines

### Adding New Tools
1. Create focused, single-purpose tools
2. Include clear documentation and usage examples
3. Follow the naming convention: `tool-purpose.js`
4. Add error handling and logging

### Test Result Storage
- Store real scraping results in `test-results/`
- Include both raw API responses and extracted content
- Document test parameters and outcomes
- Create summary files for analysis

### Cleanup Policy
- Keep tools that demonstrate functionality
- Archive old test results with timestamps
- Remove temporary or debugging files
- Maintain working examples for future reference

## ğŸš€ Usage Examples

### Testing New Websites
```bash
# Test single page
curl -X POST http://localhost:3000/api/v1/test/scrape \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com", "formats": ["markdown"]}'

# Test multi-page crawling
node experimental/tools/simple-crawler.js "https://example.com" 2 5
```

### Validating Functionality
```bash
# Run health check
curl http://localhost:3000/api/v1/health

# Check queue statistics
curl http://localhost:3000/api/v1/health/queues
```

## ğŸ“ˆ Evolution

This experimental directory will evolve with Ocean Scraper development:

1. **Phase 1** âœ…: Basic scraping validation (completed)
2. **Phase 2** âœ…: Multi-page crawling demo (completed)
3. **Phase 3**: VPN integration testing
4. **Phase 4**: Performance and scale testing
5. **Phase 5**: Advanced feature demonstrations

## ğŸ¯ Purpose

The experimental directory serves to:

- **Validate** Ocean Scraper functionality on real websites
- **Demonstrate** advanced capabilities like multi-page crawling
- **Preserve** test results for analysis and comparison
- **Provide** tools for development and debugging
- **Document** real-world performance and compatibility

All tools and tests here are designed to be non-destructive and respectful of target websites.